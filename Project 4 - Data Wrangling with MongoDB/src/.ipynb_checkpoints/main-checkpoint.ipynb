{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from lxml import etree as le\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 : Getting started with the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the dataset using Overpass API from OpenStreetMap website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Latitude boundaries\n",
    "#START_LAT = 51.52\n",
    "#END_LAT = 51.53\n",
    "\n",
    "#START_LAT = 33.85\n",
    "#END_LAT = 33.87\n",
    "\n",
    "START_LAT = 33.86\n",
    "END_LAT = 33.87\n",
    "### Longitude boundaries\n",
    "#START_LON = 0\n",
    "#END_LON = 0.1\n",
    "\n",
    "#START_LON = -118.38\n",
    "#END_LON = -118.35\n",
    "\n",
    "START_LON = -118.36\n",
    "END_LON = -118.35\n",
    "### Overpass API URL\n",
    "URL = 'http://overpass-api.de/api/map?bbox={},{},{},{}'.format(START_LON, START_LAT, END_LON, END_LAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### File details to save map data\n",
    "DIR = '/Users/sourabh/Desktop/Udacity/DAND/P4 - Data Wrangling/project/P4_OSM_Data_Wrangling/files'\n",
    "#filename='map_data_sample.osm'\n",
    "filename = 'map_bangalore.osm'\n",
    "FILENAME = os.path.join(DIR, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_osm_data(URL, filename, timeout=30):\n",
    "    \"\"\"\n",
    "    This function will request the Overpass API URL to get map data\n",
    "    according to the Lat & Lon boundaries provided.\n",
    "    It also accepts an optional parameter as timeout to wait for\n",
    "    specified time until timeout.\n",
    "    The data will be written to the output file mentioned\n",
    "    \"\"\"\n",
    "    print \"Requesting URL :: \", URL \n",
    "    r = requests.get(URL, stream=True, timeout=timeout)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        print 'Request successful !!!'\n",
    "        with open(filename, 'wb') as f:\n",
    "            print \"Downloading data to file.\"\n",
    "            i = 0\n",
    "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                if chunk:\n",
    "                    i += 1\n",
    "                    f.write(chunk)\n",
    "                    sys.stdout.write(\"\\r%s\" % ( ('.' * i) ) )    \n",
    "                    sys.stdout.flush()\n",
    "\n",
    "        print '\\nDownload finished. \\n{} is ready.'.format(filename)\n",
    "        print 'File Size :: {} MB'.format(round(os.path.getsize(FILENAME) / (1024.0 * 1024), 3) )\n",
    "    else:\n",
    "        print \"Bad Request...\\n\\n\", r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting URL ::  http://overpass-api.de/api/map?bbox=-118.36,33.86,-118.35,33.87\n",
      "Request successful !!!\n",
      "Downloading data to file.\n",
      "......................\n",
      "Download finished. \n",
      "/Users/sourabh/Desktop/Udacity/DAND/P4 - Data Wrangling/project/P4_OSM_Data_Wrangling/files/map_bangalore.osm is ready.\n",
      "File Size :: 2.477 MB\n"
     ]
    }
   ],
   "source": [
    "### Download Map data\n",
    "download_osm_data(URL=URL, filename=FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Functions that will help getting a summary of the XML document\n",
    "def sort(data, reverse = False):\n",
    "    \"\"\"\n",
    "    This is a helper function that will sort a dictionary contents according to values in ASC or DESC order.\n",
    "    \"\"\"\n",
    "    for key, value in data.items():\n",
    "        return { key: [(kk, vv) for vv, kk in sorted([(v, k) for k, v in value.items()], reverse=reverse)] }\n",
    "        \n",
    "\n",
    "def gather_element_counts_levels(doc, tag_counts={}, tag_levels={}, attrib_counts={}):\n",
    "    \"\"\"\n",
    "    This is a utility function that will recursively get the root element of the\n",
    "    XML file and will find all the tags being used in the XML. It will\n",
    "    find the level of each tag(root tag being at level 1), and also count\n",
    "    the number of times the tags appeared.\n",
    "\n",
    "    :param root: Root element of the XML\n",
    "    :param level: Level of the root\n",
    "    :param tags: A dictionary object representing tag counts\n",
    "    :param levels: A dictionary object representing level of each tag\n",
    "\n",
    "    :return: A list object containing the root element, tag counts & levels\n",
    "    \"\"\"\n",
    "    for elem in doc.iter():\n",
    "        tag = elem.tag\n",
    "        tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "\n",
    "        for attr in elem.attrib:\n",
    "            attr = tag + ':' + attr\n",
    "            attrib_counts[attr] = attrib_counts.get(attr, 0) + 1\n",
    "\n",
    "        i = 1\n",
    "        for ancestor in elem.iterancestors():\n",
    "            i += 1\n",
    "        tag_levels[tag] = i\n",
    "    return [{\"root\": doc.getroot().tag}, \\\n",
    "            {\"tag_counts\": tag_counts}, \\\n",
    "            {\"tag_levels\": tag_levels}, \\\n",
    "            {\"attrib_counts\": attrib_counts}]\n",
    "    \n",
    "\n",
    "def get_XML_stats(doc):\n",
    "    \"\"\"\n",
    "    This function will gather basic statistics for the input XML file. This includes\n",
    "    getting the root tag, and finding all the tags being used with the levels & counts.\n",
    "    :param filename: Input OSM XML file to parse\n",
    "    :return: dictionary containing basic statistics like tag counts, root tag etc.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    data = []\n",
    "    data = gather_element_counts_levels(doc, {}, {}, {})\n",
    "    \n",
    "    data[1] = sort(data[1], reverse=True)\n",
    "    data[2] = sort(data[2])\n",
    "    data[3] = sort(data[3], reverse=True)\n",
    "    \n",
    "    print 'Run time to extract statistics :: {} seconds'.format(round(time.time() - start, 3))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def almost_within(num, lower, upper, tolerance):\n",
    "    \"\"\"\n",
    "    Function that will check if a numeric value is within an interval or not with some provived tolerance.\n",
    "    \"\"\"\n",
    "    return (num >= lower-tolerance and num <= upper+tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read the XML file :: 0.117 seconds\n"
     ]
    }
   ],
   "source": [
    "### Parse the XML file\n",
    "start = time.time()\n",
    "doc = le.parse(FILENAME)\n",
    "print 'Time to read the XML file :: {} seconds'.format(round(time.time() - start, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time to extract statistics :: 0.204 seconds\n",
      "[{'root': 'osm'},\n",
      " {'tag_counts': [('nd', 11863),\n",
      "                 ('node', 10703),\n",
      "                 ('tag', 7430),\n",
      "                 ('way', 1116),\n",
      "                 ('member', 563),\n",
      "                 ('relation', 11),\n",
      "                 ('osm', 1),\n",
      "                 ('note', 1),\n",
      "                 ('meta', 1),\n",
      "                 ('bounds', 1)]},\n",
      " {'tag_levels': [('osm', 1),\n",
      "                 ('bounds', 2),\n",
      "                 ('meta', 2),\n",
      "                 ('node', 2),\n",
      "                 ('note', 2),\n",
      "                 ('relation', 2),\n",
      "                 ('way', 2),\n",
      "                 ('member', 3),\n",
      "                 ('nd', 3),\n",
      "                 ('tag', 3)]},\n",
      " {'attrib_counts': [('nd:ref', 11863),\n",
      "                    ('node:version', 10703),\n",
      "                    ('node:user', 10703),\n",
      "                    ('node:uid', 10703),\n",
      "                    ('node:timestamp', 10703),\n",
      "                    ('node:lon', 10703),\n",
      "                    ('node:lat', 10703),\n",
      "                    ('node:id', 10703),\n",
      "                    ('node:changeset', 10703),\n",
      "                    ('tag:v', 7430),\n",
      "                    ('tag:k', 7430),\n",
      "                    ('way:version', 1116),\n",
      "                    ('way:user', 1116),\n",
      "                    ('way:uid', 1116),\n",
      "                    ('way:timestamp', 1116),\n",
      "                    ('way:id', 1116),\n",
      "                    ('way:changeset', 1116),\n",
      "                    ('member:type', 563),\n",
      "                    ('member:role', 563),\n",
      "                    ('member:ref', 563),\n",
      "                    ('relation:version', 11),\n",
      "                    ('relation:user', 11),\n",
      "                    ('relation:uid', 11),\n",
      "                    ('relation:timestamp', 11),\n",
      "                    ('relation:id', 11),\n",
      "                    ('relation:changeset', 11),\n",
      "                    ('osm:version', 1),\n",
      "                    ('osm:generator', 1),\n",
      "                    ('meta:osm_base', 1),\n",
      "                    ('bounds:minlon', 1),\n",
      "                    ('bounds:minlat', 1),\n",
      "                    ('bounds:maxlon', 1),\n",
      "                    ('bounds:maxlat', 1)]}]\n"
     ]
    }
   ],
   "source": [
    "### Get XML summary\n",
    "stats = get_XML_stats(doc)\n",
    "pprint.pprint(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 : Audit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audit the latitude & longitude values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['33.8600000', '-118.3600000', '33.8700000', '-118.3500000']\n",
      "[33.86, -118.35, -118.36, 33.87]\n"
     ]
    }
   ],
   "source": [
    "# Check the lat & lon boundaries\n",
    "print doc.find(\"bounds\").attrib.values()\n",
    "print [START_LAT, END_LON, START_LON, END_LAT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit individual attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ID should be unique and numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_integer(x):\n",
    "    \"\"\"This is a helper function used to find out if a number is integer or not\"\"\"\n",
    "    try:\n",
    "        x = int(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def is_float(x):\n",
    "    \"\"\"This is a helper function used to find out if a number is float or not\"\"\"\n",
    "    try:\n",
    "        x = float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def is_datetime_TZ(t):\n",
    "    try:\n",
    "        t = datetime.strptime(t, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def audit_ID(ID, ID_LIST):\n",
    "    \"\"\"Function to audit the ID fields of node, way & relation elements\"\"\"\n",
    "    if ID in ID_LIST:\n",
    "        print 'Duplicate {} ID'.format(type)\n",
    "        return False\n",
    "    else:\n",
    "        return is_integer(ID)\n",
    "    \n",
    "def audit_latitude_longitude(lat, lon, tolerance=0.005):\n",
    "    \"\"\"\n",
    "    Function to audit the Latitude & Longitude fields.\n",
    "    Also it will check if the lat & lon is within bounds.\n",
    "    \"\"\"\n",
    "    r = False\n",
    "    if is_float(lat) and is_float(lon):\n",
    "        lat = float(lat)\n",
    "        lon = float(lon)\n",
    "        if almost_within(lat, START_LAT, END_LAT, tolerance) and almost_within(lon, START_LON, END_LON, tolerance):\n",
    "            r = True\n",
    "    \n",
    "    return r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_level_2_elements(doc):\n",
    "    start = time.time()\n",
    "    IDs_to_clear = []\n",
    "    ID_LIST = {\"node\":[], \"way\":[], \"relation\":[]}\n",
    "    \n",
    "    for elem in doc.iter(\"node\", \"way\", \"relation\"):\n",
    "        remove_flag = False\n",
    "        tag = elem.tag\n",
    "        attr = elem.attrib\n",
    "        \n",
    "        ID = attr[\"id\"]\n",
    "        version = attr[\"version\"]\n",
    "        timestamp = attr[\"timestamp\"]\n",
    "        changeset = attr[\"changeset\"]\n",
    "        uid = attr[\"uid\"]\n",
    "\n",
    "        if not audit_ID(ID, ID_LIST[tag]):\n",
    "            #print \"ID error :: \", elem, ID\n",
    "            remove_flag = True\n",
    "\n",
    "        elif (tag == \"node\") and (not audit_latitude_longitude(attr[\"lat\"], attr[\"lon\"]) ):\n",
    "            #print \"Problem in Lat & Lon values \", ID, lat, lon\n",
    "            remove_flag = True\n",
    "\n",
    "        elif not is_integer(version):\n",
    "            #print \"Version problem \", ID, version\n",
    "            remove_flag = True\n",
    "\n",
    "        elif not is_datetime_TZ(timestamp):\n",
    "            #print \"Timestamp problem \", ID, timestamp\n",
    "            remove_flag = True\n",
    "\n",
    "        elif not is_integer(changeset):\n",
    "            #print \"Changeset is not integer \", ID, changeset\n",
    "            remove_flag = True\n",
    "\n",
    "        elif not is_integer(uid):\n",
    "            #print \"UID is not integer \", ID, uid\n",
    "            remove_flag = True\n",
    "\n",
    "        if remove_flag:\n",
    "            IDs_to_clear.append(ID)\n",
    "            tmp = elem\n",
    "            elem = elem.getnext()\n",
    "            tmp.getparent().remove(tmp)\n",
    "            #elem.clear()\n",
    "        else :\n",
    "            ID_LIST[tag].append(ID)\n",
    "            \n",
    "    print 'Time Taken :: ', round(time.time() - start, 3), \" seconds\"\n",
    "    return doc, IDs_to_clear\n",
    "\n",
    "            \n",
    "def clear_invalid_node_references(doc, IDs_to_remove):    \n",
    "    start = time.time()\n",
    "    for elem in doc.iter(\"nd\"):\n",
    "        ref = elem.attrib[\"ref\"]\n",
    "        \n",
    "        if ref in IDs_to_remove:\n",
    "            tmp = elem\n",
    "            elem = elem.getnext()\n",
    "            tmp.getparent().remove(tmp)\n",
    "            \n",
    "    print 'Time Taken :: ', round(time.time() - start, 3), \" seconds\"\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken ::  1.312  seconds\n"
     ]
    }
   ],
   "source": [
    "doc, IDs_to_remove = audit_level_2_elements(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IDs_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken ::  0.049  seconds\n"
     ]
    }
   ],
   "source": [
    "doc = clear_invalid_node_references(doc, IDs_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time to extract statistics :: 0.197 seconds\n",
      "[{'root': 'osm'},\n",
      " {'tag_counts': [('nd', 11689),\n",
      "                 ('node', 10529),\n",
      "                 ('tag', 7405),\n",
      "                 ('way', 1116),\n",
      "                 ('member', 563),\n",
      "                 ('relation', 11),\n",
      "                 ('osm', 1),\n",
      "                 ('note', 1),\n",
      "                 ('meta', 1),\n",
      "                 ('bounds', 1)]},\n",
      " {'tag_levels': [('osm', 1),\n",
      "                 ('bounds', 2),\n",
      "                 ('meta', 2),\n",
      "                 ('node', 2),\n",
      "                 ('note', 2),\n",
      "                 ('relation', 2),\n",
      "                 ('way', 2),\n",
      "                 ('member', 3),\n",
      "                 ('nd', 3),\n",
      "                 ('tag', 3)]},\n",
      " {'attrib_counts': [('nd:ref', 11689),\n",
      "                    ('node:version', 10529),\n",
      "                    ('node:user', 10529),\n",
      "                    ('node:uid', 10529),\n",
      "                    ('node:timestamp', 10529),\n",
      "                    ('node:lon', 10529),\n",
      "                    ('node:lat', 10529),\n",
      "                    ('node:id', 10529),\n",
      "                    ('node:changeset', 10529),\n",
      "                    ('tag:v', 7405),\n",
      "                    ('tag:k', 7405),\n",
      "                    ('way:version', 1116),\n",
      "                    ('way:user', 1116),\n",
      "                    ('way:uid', 1116),\n",
      "                    ('way:timestamp', 1116),\n",
      "                    ('way:id', 1116),\n",
      "                    ('way:changeset', 1116),\n",
      "                    ('member:type', 563),\n",
      "                    ('member:role', 563),\n",
      "                    ('member:ref', 563),\n",
      "                    ('relation:version', 11),\n",
      "                    ('relation:user', 11),\n",
      "                    ('relation:uid', 11),\n",
      "                    ('relation:timestamp', 11),\n",
      "                    ('relation:id', 11),\n",
      "                    ('relation:changeset', 11),\n",
      "                    ('osm:version', 1),\n",
      "                    ('osm:generator', 1),\n",
      "                    ('meta:osm_base', 1),\n",
      "                    ('bounds:minlon', 1),\n",
      "                    ('bounds:minlat', 1),\n",
      "                    ('bounds:maxlon', 1),\n",
      "                    ('bounds:maxlat', 1)]}]\n"
     ]
    }
   ],
   "source": [
    "### Get XML summary\n",
    "stats = get_XML_stats(doc)\n",
    "pprint.pprint(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys and occurrence\n",
      "\n",
      "[('building', 1003),\n",
      " ('ele', 949),\n",
      " ('lacounty:bld_id', 946),\n",
      " ('lacounty:ain', 946),\n",
      " ('height', 946),\n",
      " ('start_date', 892),\n",
      " ('building:units', 857),\n",
      " ('highway', 95),\n",
      " ('name', 91),\n",
      " ('lanes', 54),\n",
      " ('oneway', 31),\n",
      " ('tiger:name_base', 30),\n",
      " ('tiger:county', 30),\n",
      " ('tiger:cfcc', 30),\n",
      " ('tiger:zip_left', 27),\n",
      " ('tiger:name_type', 27),\n",
      " ('tiger:reviewed', 26),\n",
      " ('tiger:zip_right', 25),\n",
      " ('ref', 20),\n",
      " ('source:hgv:national_network', 19),\n",
      " ('old_ref:legislative', 19),\n",
      " ('old_ref', 19),\n",
      " ('hgv:national_network', 19),\n",
      " ('hgv', 19),\n",
      " ('power', 15),\n",
      " ('turn:lanes', 13),\n",
      " ('lanes:forward', 13),\n",
      " ('lanes:backward', 13),\n",
      " ('tiger:tlid', 12),\n",
      " ('tiger:source', 12),\n",
      " ('tiger:separated', 12),\n",
      " ('type', 11),\n",
      " ('building:use', 7),\n",
      " ('turn:lanes:backward', 6),\n",
      " ('tiger:name_direction_prefix', 6),\n",
      " ('landuse', 6),\n",
      " ('amenity', 6),\n",
      " ('operator', 5),\n",
      " ('leisure', 5),\n",
      " ('turn:lanes:forward', 4),\n",
      " ('source', 4),\n",
      " ('shop', 4),\n",
      " ('railway', 4),\n",
      " ('gnis:feature_id', 4),\n",
      " ('usage', 3),\n",
      " ('service', 3),\n",
      " ('route', 3),\n",
      " ('owner', 3),\n",
      " ('layer', 3),\n",
      " ('gnis:state_id', 3),\n",
      " ('gnis:created', 3),\n",
      " ('gnis:county_id', 3),\n",
      " ('gauge', 3),\n",
      " ('electrified', 3),\n",
      " ('cycleway', 3),\n",
      " ('boundary', 3),\n",
      " ('border_type', 3),\n",
      " ('admin_level', 3),\n",
      " ('wires', 2),\n",
      " ('wikipedia', 2),\n",
      " ('wikidata', 2),\n",
      " ('website', 2),\n",
      " ('voltage', 2),\n",
      " ('tiger:STATEFP', 2),\n",
      " ('tiger:PLCIDFP', 2),\n",
      " ('tiger:PLACENS', 2),\n",
      " ('tiger:PLACEFP', 2),\n",
      " ('tiger:PCINECTA', 2),\n",
      " ('tiger:PCICBSA', 2),\n",
      " ('tiger:NAMELSAD', 2),\n",
      " ('tiger:NAME', 2),\n",
      " ('tiger:MTFCC', 2),\n",
      " ('tiger:LSAD', 2),\n",
      " ('tiger:FUNCSTAT', 2),\n",
      " ('tiger:CPI', 2),\n",
      " ('tiger:CLASSFP', 2),\n",
      " ('place', 2),\n",
      " ('is_in:state_code', 2),\n",
      " ('is_in:state', 2),\n",
      " ('is_in:iso_3166_2', 2),\n",
      " ('is_in:country_code', 2),\n",
      " ('is_in:country', 2),\n",
      " ('is_in', 2),\n",
      " ('frequency', 2),\n",
      " ('fixme', 2),\n",
      " ('cuisine', 2),\n",
      " ('circuits', 2),\n",
      " ('cables', 2),\n",
      " ('addr:street', 2),\n",
      " ('addr:postcode', 2),\n",
      " ('addr:housenumber', 2),\n",
      " ('tiger:name_type_1', 1),\n",
      " ('tiger:name_direction_prefix_1', 1),\n",
      " ('tiger:name_base_1', 1),\n",
      " ('parking', 1),\n",
      " ('opening_hours', 1),\n",
      " ('office', 1),\n",
      " ('note', 1),\n",
      " ('network', 1),\n",
      " ('name_1', 1),\n",
      " ('name:en', 1),\n",
      " ('gnis:edited', 1),\n",
      " ('craft', 1),\n",
      " ('bridge', 1),\n",
      " ('addr:state', 1),\n",
      " ('addr:city', 1)]\n",
      "\n",
      "--- 0.102547168732 seconds ---\n"
     ]
    }
   ],
   "source": [
    "### Audit Tags\n",
    "def count_tag_keys(doc):\n",
    "    keys = {}\n",
    "    for elem in doc.iter(\"tag\"):\n",
    "        key = elem.attrib.get('k')\n",
    "        if key:\n",
    "            if key not in keys:\n",
    "                keys[key] = 1\n",
    "            else:\n",
    "                keys[key] += 1\n",
    "    return keys\n",
    "\n",
    "start_time = time.time()\n",
    "keys = count_tag_keys(doc)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in keys.items()], reverse=True)]\n",
    "\n",
    "print 'Keys and occurrence\\n'\n",
    "pprint.pprint(sorted_by_occurrence)\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    k = element.attrib[\"k\"]\n",
    "    \n",
    "    if problemchars.match(k):\n",
    "        keys[\"problemchars\"] += 1\n",
    "    elif lower_colon.match(k):\n",
    "        keys[\"lower_colon\"] += 1\n",
    "    elif lower.match(k):\n",
    "        keys[\"lower\"] += 1\n",
    "    else:\n",
    "        keys[\"other\"] += 1\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(doc):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for element in doc.iter(\"tag\"):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 4243, 'lower_colon': 3101, 'other': 61, 'problemchars': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_map(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "TAG_KEYS = [\"amenity\", \"cuisine\", \"name\", \"phone\", \"website\"]\n",
    "\n",
    "expected_st_names = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "                     \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "street_types = defaultdict(set)\n",
    "\n",
    "mapping = { \"pl\": \"Place\",\n",
    "            \"st\": \"Street\",\n",
    "            \"ave\": \"Avenue\",\n",
    "            \"ave.\": \"Avenue\",\n",
    "            \"rd\": \"Road\",\n",
    "            \"rd.\": \"Road\",\n",
    "            \"w\": \"West\",\n",
    "            \"n\": \"North\",\n",
    "            \"s\": \"South\",\n",
    "            \"e\": \"East\",\n",
    "            \"blvd\":\"Boulevard\",\n",
    "            \"sr\": \"Drive\",\n",
    "            \"ct\": \"Court\",\n",
    "            \"ne\": \"Northeast\",\n",
    "            \"se\": \"Southeast\",\n",
    "            \"nw\": \"Northwest\",\n",
    "            \"sw\": \"Southwest\",\n",
    "            \"dr\": \"Drive\",\n",
    "            \"sq\": \"Square\",\n",
    "            \"st\": \"Street\",\n",
    "            \"st.\": \"Street\",\n",
    "            \"ln\": \"Lane\",\n",
    "            \"trl\": \"Trail\",\n",
    "            \"pkwy\": \"Parkway\",\n",
    "            \"ste\": \"Suite\",\n",
    "            \"lp\": \"Loop\",\n",
    "            \"hwy\": \"Highway\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Validate the postcodes -- England Post codes\n",
    "def audit_postcode(post_code):\n",
    "    #uk_postcode_format = re.compile(r'^[A-Z][A-Z]?[0-9][0-9]?[A-Z]? [0-9][A-Z][A-Z]$')\n",
    "    us_postcode_format = re.compile(\"^\\d{5}$\")\n",
    "    \n",
    "    if us_postcode_format.match(post_code):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Clean Street Names\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected_st_names:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for element in doc.iter(\"tag\"):\n",
    "    k, v = element.attrib[\"k\"], element.attrib[\"v\"]\n",
    "    if k.startswith(\"addr:street\"):\n",
    "        audit_street_type(street_types, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set, {})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_street_name(street):\n",
    "    s = street.split()[-1].lower()\n",
    "    street = street.split()[:-1] + [mapping[s]]\n",
    "    return ' '.join(street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_empty_values(d):\n",
    "    for k, v in d.items():\n",
    "        if v == None or len(v) == 0:\n",
    "            del d[k]\n",
    "        elif type(v) == dict or type(v) == OrderedDict:\n",
    "            return remove_empty_values(v)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element):\n",
    "    node = {\"created\": OrderedDict(), \"type\": element.tag}\n",
    "        \n",
    "    attrs = element.attrib\n",
    "    lat = None\n",
    "    lon = None\n",
    "    \n",
    "    for attr in attrs:\n",
    "        if attr in CREATED:\n",
    "            node[\"created\"][attr] = attrs[attr]\n",
    "        elif attr == \"lat\":\n",
    "            lat = float(attrs[attr])\n",
    "        elif attr == \"lon\":\n",
    "            lon = float(attrs[attr])\n",
    "        else:\n",
    "            node[attr] = attrs[attr]\n",
    "            \n",
    "    if lat:\n",
    "        node[\"pos\"] = [lat] + [lon]\n",
    "        \n",
    "    for child in element:\n",
    "        if child.tag == \"nd\":\n",
    "            node[\"node_refs\"] = node.get(\"node_refs\", []) + [child.attrib[\"ref\"]]\n",
    "        else:\n",
    "            k, v = child.attrib[\"k\"], child.attrib[\"v\"]\n",
    "            \n",
    "            if problemchars.match(k):\n",
    "                continue\n",
    "                \n",
    "            if k.startswith(\"addr\") and k.count(\":\") == 1:\n",
    "                node[\"address\"] = node.get(\"address\", {})\n",
    "                    \n",
    "                if \"housenumber\" in k:\n",
    "                    node[\"address\"][\"housenumber\"] = v\n",
    "                        \n",
    "                elif \"street\" in k:\n",
    "                    if v.split()[-1].lower() in mapping.keys(): \n",
    "                        node[\"address\"][\"street\"] = clean_street_name(v)\n",
    "                        print \"Street Name corrected --- {} ==> {}\".format(v, node[\"address\"][\"street\"])\n",
    "                    else:\n",
    "                        node[\"address\"][\"street\"] = v\n",
    "                    \n",
    "                elif \"city\" in k:\n",
    "                    node[\"address\"][\"city\"] = v\n",
    "                    \n",
    "                elif \"state\" in k:\n",
    "                    node[\"address\"][\"state\"] = v\n",
    "                \n",
    "                elif \"postcode\" in k:\n",
    "                    if audit_postcode(v):\n",
    "                        node[\"address\"][\"postcode\"] = v\n",
    "                    \n",
    "            else:\n",
    "                if k in TAG_KEYS:\n",
    "                    node[k] = v\n",
    "            \n",
    "            #node = remove_None_values(node)\n",
    "        \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element_OD(element):\n",
    "    CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "    ADDRESS_ITEMS = [\"housenumber\", \"street\", \"city\", \"state\", \"postcode\"]\n",
    "\n",
    "    node = OrderedDict({})\n",
    "    \n",
    "    node[\"id\"] = \"\"\n",
    "    node[\"type\"] = element.tag\n",
    "    node[\"created\"] = OrderedDict()\n",
    "    node[\"pos\"] = \"\"\n",
    "    node[\"address\"] = OrderedDict()\n",
    "    node[\"amenity\"] = \"\"\n",
    "    node[\"cuisine\"] = \"\"\n",
    "    node[\"name\"] = \"\"\n",
    "    node[\"phone\"] = \"\"\n",
    "    node[\"website\"] = \"\"\n",
    "    node[\"node_refs\"] = []\n",
    "        \n",
    "    for key in node.keys():\n",
    "        if key == \"created\":\n",
    "            for k in CREATED:\n",
    "                node[key][k]= \"\"\n",
    "            \n",
    "        if key == \"address\":\n",
    "            for k in ADDRESS_ITEMS:\n",
    "                node[key][k] = \"\" \n",
    "            \n",
    "    attrs = element.attrib\n",
    "    lat = None\n",
    "    lon = None\n",
    "    \n",
    "    for attr in attrs:\n",
    "        if attr in CREATED:\n",
    "            if attr == \"timestamp\":\n",
    "                node[\"created\"][attr] = datetime.strptime(attrs[attr], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            else:\n",
    "                node[\"created\"][attr] = attrs[attr]\n",
    "        elif attr == \"lat\":\n",
    "            lat = float(attrs[attr])\n",
    "        elif attr == \"lon\":\n",
    "            lon = float(attrs[attr])\n",
    "        else:\n",
    "            node[attr] = attrs[attr]\n",
    "            \n",
    "    if lat:\n",
    "        node[\"pos\"] = [lat] + [lon]\n",
    "        \n",
    "    for child in element:\n",
    "        if child.tag == \"nd\":\n",
    "            node[\"node_refs\"] = node.get(\"node_refs\", []) + [int(child.attrib[\"ref\"])]\n",
    "        else:\n",
    "            k, v = child.attrib[\"k\"], child.attrib[\"v\"]\n",
    "            \n",
    "            if problemchars.match(k):\n",
    "                continue\n",
    "                \n",
    "            if k.startswith(\"addr\") and k.count(\":\") == 1:\n",
    "                node[\"address\"] = node.get(\"address\", {})\n",
    "                    \n",
    "                if \"housenumber\" in k:\n",
    "                    node[\"address\"][\"housenumber\"] = v\n",
    "                        \n",
    "                elif \"street\" in k:\n",
    "                    if v.split()[-1].lower() in mapping.keys(): \n",
    "                        node[\"address\"][\"street\"] = clean_street_name(v)\n",
    "                        print \"Street Name corrected --- {} ==> {}\".format(v, node[\"address\"][\"street\"])\n",
    "                    else:\n",
    "                        node[\"address\"][\"street\"] = v\n",
    "                    \n",
    "                elif \"city\" in k:\n",
    "                    node[\"address\"][\"city\"] = v\n",
    "                    \n",
    "                elif \"state\" in k:\n",
    "                    node[\"address\"][\"state\"] = v\n",
    "                \n",
    "                elif \"postcode\" in k:\n",
    "                    if audit_postcode(v):\n",
    "                        node[\"address\"][\"postcode\"] = v\n",
    "                    \n",
    "            else:\n",
    "                if k in TAG_KEYS:\n",
    "                    node[k] = v\n",
    "            \n",
    "    #node = remove_empty_values(node)\n",
    "        \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_json_docs_OD(doc):\n",
    "    data = []\n",
    "    \n",
    "    for element in doc.iter(\"node\", \"way\"):\n",
    "        el = shape_element_OD(element)\n",
    "\n",
    "        for key, value in el.items():\n",
    "            if type(value) == OrderedDict:\n",
    "                for k, v in value.items():\n",
    "                    if len(v) == 0:\n",
    "                        del el[key][k]\n",
    "\n",
    "            if len(value) == 0:\n",
    "                    del el[key]\n",
    "    \n",
    "        data.append(el)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_json_OD(file_in, pretty = False):\n",
    "    start = time.time()\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    print 'Writing data to JSON file --- \\n', file_out\n",
    "    \n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for node in create_json_docs_OD(doc):\n",
    "            if node:\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(node, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(node) + \"\\n\")\n",
    "    \n",
    "    print \"JSON file done.\"\n",
    "    print 'File Size :: {} MB'.format(round(os.path.getsize(file_out) / (1024.0 * 1024), 3) )\n",
    "    print 'Time Taken :: ', round(time.time() - start, 3), \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_json_docs(doc):\n",
    "    HEADER = [\"id\", \"type\", \"created\", \"pos\", \"address\", \"amenity\", \"cuisine\", \"name\", \"phone\", \"website\", \"node_refs\"]\n",
    "    ADDRESS_ITEMS = [\"housenumber\", \"street\", \"city\", \"state\", \"postcode\"]\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for element in doc.iter(\"node\", \"way\"):\n",
    "        data_node = OrderedDict()\n",
    "        el = shape_element(element)\n",
    "\n",
    "        elem_keys = el.keys()\n",
    "        \n",
    "        for item in HEADER:\n",
    "            if item in elem_keys:\n",
    "                if item == \"created\":\n",
    "                    data_node[item] = OrderedDict()\n",
    "                    #created_keys = el[item].keys()\n",
    "                    for c_item in [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\" ]:\n",
    "                        try:\n",
    "                            data_node[item][c_item] = el[item][c_item]\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                if item == \"address\":\n",
    "                    data_node[item] = OrderedDict()\n",
    "                    #address_keys = el[item].keys()\n",
    "                    for c_item in ADDRESS_ITEMS:\n",
    "                        #if c_item in address_keys:\n",
    "                        #    node[item][c_item] = el[item][c_item]\n",
    "                        try:\n",
    "                            data_node[item][c_item] = el[item][c_item]\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                else:\n",
    "                    data_node[item] = el[item]\n",
    "\n",
    "        data.append(data_node)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_json(file_in, pretty = False):\n",
    "    start = time.time()\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    print 'Writing data to JSON file --- \\n', file_out\n",
    "    \n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for node in create_json_docs(doc):\n",
    "            if node:\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(node, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(node) + \"\\n\")\n",
    "    \n",
    "    print \"JSON file done.\"\n",
    "    print 'File Size :: {} MB'.format(round(os.path.getsize(file_out) / (1024.0 * 1024), 3) )\n",
    "    print 'Time Taken :: ', round(time.time() - start, 3), \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to JSON file --- \n",
      "/Users/sourabh/Desktop/Udacity/DAND/P4 - Data Wrangling/project/P4_OSM_Data_Wrangling/files/map_bangalore.osm.json\n",
      "Street Name corrected --- Prospect Ave. ==> Prospect Avenue\n",
      "JSON file done.\n",
      "File Size :: 27.669 MB\n",
      "Time Taken ::  23.362  seconds\n"
     ]
    }
   ],
   "source": [
    "create_json(FILENAME, pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to JSON file --- \n",
      "/Users/sourabh/Desktop/Udacity/DAND/P4 - Data Wrangling/project/P4_OSM_Data_Wrangling/files/map_bangalore.osm.json\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-42839775bb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_json_OD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-83ab1439ecb7>\u001b[0m in \u001b[0;36mcreate_json_OD\u001b[0;34m(file_in, pretty)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_json_docs_OD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpretty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-210-69c1db4ca7cc>\u001b[0m in \u001b[0;36mcreate_json_docs_OD\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"node\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"way\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_element_OD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iter'"
     ]
    }
   ],
   "source": [
    "create_json_OD(FILENAME, pretty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load JSON file into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running below cmd to load json file data into mongodb(test -> osm) \n",
      " mongoimport --db test --collection osm --drop --file \"/Users/sourabh/Desktop/Udacity/DAND/P4 - Data Wrangling/project/P4_OSM_Data_Wrangling/files/map_bangalore.osm\".json\n",
      "... Import Successful ...\n",
      "Time Taken ::  0.437  seconds\n"
     ]
    }
   ],
   "source": [
    "### Import JSON data into MongoDB -- DB Name -- test, collection name -- osm\n",
    "start = time.time()\n",
    "json_file = '\"{0}\".json'.format(FILENAME)\n",
    "import_cmd = \"mongoimport --db test --collection osm --drop --file {}\".format(json_file)\n",
    "\n",
    "print \"Running below cmd to load json file data into mongodb(test -> osm) \\n {}\".format(import_cmd)\n",
    "\n",
    "if os.system(import_cmd) == 0:\n",
    "    print \"... Import Successful ...\"\n",
    "print 'Time Taken :: ', round(time.time() - start, 3), \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)\n"
     ]
    }
   ],
   "source": [
    "### connect to mongo data\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "print client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'test')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.test\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'test'), u'osm')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = db.osm\n",
    "coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11645"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total documents\n",
    "coll.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('58c57a4186d2fbc52ba3b8ab'),\n",
      " u'created': {u'changeset': u'37825826',\n",
      "              u'timestamp': u'2016-03-14T17:31:01Z',\n",
      "              u'uid': u'2748195',\n",
      "              u'user': u'karitotp',\n",
      "              u'version': u'12'},\n",
      " u'id': u'21098512',\n",
      " u'pos': [33.8578136, -118.3535925],\n",
      " u'type': u'node'}\n"
     ]
    }
   ],
   "source": [
    "# Find One document\n",
    "pprint.pprint(coll.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.find({\"created.uid\":\"86782\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('58c651e7fe2a51225b8522ea'),\n",
      " u'created': {u'changeset': u'3291606',\n",
      "              u'timestamp': u'2009-12-04T21:42:18Z',\n",
      "              u'uid': u'86782',\n",
      "              u'user': u'maxtheheathen',\n",
      "              u'version': u'6'},\n",
      " u'id': u'122443473',\n",
      " u'pos': [33.8599625, -118.3527119],\n",
      " u'type': u'node'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(coll.find_one({\"created.uid\":\"86782\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.find({\"address.postcode\": \"90278\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "{u'_id': ObjectId('58c651e7fe2a51225b854bf0'),\n",
      " u'address': {u'city': u'Redondo Beach',\n",
      "              u'housenumber': u'2907',\n",
      "              u'postcode': u'90278',\n",
      "              u'state': u'CA',\n",
      "              u'street': u'West 182nd Street'},\n",
      " u'created': {u'changeset': u'44316658',\n",
      "              u'timestamp': u'2016-12-11T06:54:08Z',\n",
      "              u'uid': u'104962',\n",
      "              u'user': u'techlady',\n",
      "              u'version': u'2'},\n",
      " u'id': u'4548769183',\n",
      " u'name': u'King Harbor Brewing Company',\n",
      " u'pos': [33.8659247, -118.3560263],\n",
      " u'type': u'node',\n",
      " u'website': u'http://www.kingharborbrewing.com'}\n",
      "<type 'dict'>\n",
      "{u'_id': ObjectId('58c651e7fe2a51225b854e98'),\n",
      " u'address': {u'housenumber': u'1401',\n",
      "              u'postcode': u'90278',\n",
      "              u'street': u'Hawthorne Boulevard'},\n",
      " u'created': {u'changeset': u'42216476',\n",
      "              u'timestamp': u'2016-09-16T22:33:33Z',\n",
      "              u'uid': u'2606959',\n",
      "              u'user': u'sctrojan79-import',\n",
      "              u'version': u'1'},\n",
      " u'id': u'442859556',\n",
      " u'node_refs': [u'4405069792',\n",
      "                u'4405069793',\n",
      "                u'4405069814',\n",
      "                u'4405069813',\n",
      "                u'4405069807',\n",
      "                u'4405069806',\n",
      "                u'4363347289',\n",
      "                u'4405069791',\n",
      "                u'4405065287',\n",
      "                u'4405065288',\n",
      "                u'4405065271',\n",
      "                u'4405065272',\n",
      "                u'4405065265',\n",
      "                u'4405065266',\n",
      "                u'4405065255',\n",
      "                u'4405065257',\n",
      "                u'4405065263',\n",
      "                u'4405065264',\n",
      "                u'4405069792'],\n",
      " u'type': u'way',\n",
      " u'website': u'http://www.tjmaxx.com'}\n"
     ]
    }
   ],
   "source": [
    "for doc in coll.find({\"address.postcode\": \"90278\"}):\n",
    "    print type(doc)\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'way'}\n",
      "{u'_id': u'node'}\n"
     ]
    }
   ],
   "source": [
    "### Find out all distinct types\n",
    "cursor = coll.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$type\"} }\n",
    "    ])\n",
    "\n",
    "for doc in cursor:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 2, u'_id': u'restaurant'}\n",
      "{u'count': 2, u'_id': u'school'}\n",
      "{u'count': 1, u'_id': u'grave_yard'}\n",
      "{u'count': 1, u'_id': u'parking'}\n"
     ]
    }
   ],
   "source": [
    "### Find out all amenity types with count\n",
    "field = \"amenity\"\n",
    "cursor = coll.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$\"+field, \"count\": {\"$sum\": 1} } },\n",
    "        {\"$match\": {\"_id\": {\"$ne\": None } } },\n",
    "        {\"$sort\": {\"count\":-1} }\n",
    "    ])\n",
    "\n",
    "for document in cursor:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 1, u'_id': u'sandwich'}\n",
      "{u'count': 1, u'_id': u'burger'}\n"
     ]
    }
   ],
   "source": [
    "### Find out all cuisine types with count\n",
    "field = \"cuisine\"\n",
    "cursor = coll.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$\"+field, \"count\": {\"$sum\": 1} } },\n",
    "        {\"$match\": {\"_id\": {\"$ne\": None } } },\n",
    "        {\"$sort\": {\"count\":-1} }\n",
    "    ])\n",
    "\n",
    "for document in cursor:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 2, u'_id': u'90278'}\n"
     ]
    }
   ],
   "source": [
    "### Find out all postcodes with count\n",
    "field = \"address.postcode\"\n",
    "cursor = coll.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$\"+field, \"count\": {\"$sum\": 1} } },\n",
    "        {\"$match\": {\"_id\": {\"$ne\": None } } },\n",
    "        {\"$sort\": {\"count\":-1} }\n",
    "    ])\n",
    "\n",
    "for document in cursor:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 3107, u'_id': u'dannykath_labuildings'}\n",
      "{u'count': 2874, u'_id': u'Luis36995_labuildings'}\n",
      "{u'count': 2286, u'_id': u'RichRico_labuildings'}\n",
      "{u'count': 2163, u'_id': u'piligab_labuildings'}\n",
      "{u'count': 555, u'_id': u'sctrojan79-import'}\n",
      "{u'count': 114, u'_id': u'Brian@Brea'}\n",
      "{u'count': 88, u'_id': u'karitotp_labuildings'}\n",
      "{u'count': 82, u'_id': u'maxtheheathen'}\n",
      "{u'count': 57, u'_id': u'StellanL'}\n",
      "{u'count': 48, u'_id': u'karitotp'}\n"
     ]
    }
   ],
   "source": [
    "### Find out Top 10 contributing users with count\n",
    "field = \"created.user\"\n",
    "cursor = coll.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$\"+field, \"count\": {\"$sum\": 1} } },\n",
    "        {\"$match\": {\"_id\": {\"$ne\": None } } },\n",
    "        {\"$sort\": {\"count\":-1} }, \n",
    "        {\"$limit\": 10}\n",
    "    ])\n",
    "\n",
    "for document in cursor:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009-12-04T21:42:18Z'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"2009-12-04T21:42:18Z\"\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2009, 12, 4, 21, 42, 18)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(t, \"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
